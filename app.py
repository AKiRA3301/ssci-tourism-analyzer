#!/usr/bin/env python3
"""
SSCIæ—…æ¸¸å­¦æœ¯è¶‹åŠ¿åˆ†æç³»ç»Ÿ - Web UIç•Œé¢
ä½¿ç”¨ Streamlit æ„å»º

è¿è¡Œæ–¹å¼: streamlit run app.py
"""

import streamlit as st
import pandas as pd
import os
import sys
import json
from datetime import datetime

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from modules.data_fetcher import DataFetcher
from modules.file_importer import FileImporter
from modules.text_processor import TextProcessor
from modules.analyzer import TrendAnalyzer
from modules.visualizer import Visualizer
from modules.ai_advisor import AIAdvisor

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SSCIæ—…æ¸¸å­¦æœ¯è¶‹åŠ¿åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 10px 20px;
        background-color: #f0f2f6;
        border-radius: 5px;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border-radius: 5px;
        border-left: 5px solid #28a745;
    }
    .warning-box {
        padding: 1rem;
        background-color: #fff3cd;
        border-radius: 5px;
        border-left: 5px solid #ffc107;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'topics' not in st.session_state:
    st.session_state.topics = None


def load_demo_data():
    """åŠ è½½æˆ–ç”ŸæˆDemoæ•°æ®"""
    from generate_demo_data import generate_demo_data
    
    demo_file = "demo_data.csv"
    if not os.path.exists(demo_file):
        generate_demo_data(200, demo_file)
    
    return pd.read_csv(demo_file)


def main():
    # æ ‡é¢˜
    st.markdown('<p class="main-header">ğŸ“Š SSCIæ—…æ¸¸å­¦æœ¯è¶‹åŠ¿åˆ†æç³»ç»Ÿ</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">æ–‡çŒ®è®¡é‡ | å…³é”®è¯æŒ–æ˜ | ç ”ç©¶ç¼ºå£è¯†åˆ« | AIè¾…åŠ©é€‰é¢˜</p>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/search-in-cloud.png", width=80)
        st.markdown("### ğŸ¯ æ“ä½œé¢æ¿")
        st.markdown("---")
        
        # æ•°æ®æ¥æºé€‰æ‹©
        data_source = st.selectbox(
            "é€‰æ‹©æ•°æ®æ¥æº",
            ["ğŸ“‚ ä¸Šä¼ æœ¬åœ°æ–‡ä»¶", "ğŸŒ ä»OpenAlexè·å–", "ğŸ² ä½¿ç”¨Demoæ•°æ®"]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ å½“å‰çŠ¶æ€")
        
        if st.session_state.data is not None:
            st.success(f"âœ… å·²åŠ è½½ {len(st.session_state.data)} æ¡æ•°æ®")
        else:
            st.warning("âš ï¸ æœªåŠ è½½æ•°æ®")
        
        if st.session_state.analysis_results is not None:
            st.success("âœ… å·²å®Œæˆåˆ†æ")
        
        st.markdown("---")
        st.markdown("### â„¹ï¸ å…³äº")
        st.markdown("""
        **ç‰ˆæœ¬**: 2.0  
        **åŠŸèƒ½**: 
        - å…³é”®è¯é¢‘ç‡åˆ†æ
        - çªå‘è¯æ£€æµ‹
        - LDAä¸»é¢˜å»ºæ¨¡
        - ç ”ç©¶ç¼ºå£è¯†åˆ«
        - AIè¾…åŠ©é€‰é¢˜
        """)
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“‚ æ•°æ®åŠ è½½", 
        "ğŸ”‘ å…³é”®è¯åˆ†æ", 
        "ğŸ§  ä¸»é¢˜å»ºæ¨¡",
        "ğŸ“ˆ å¯è§†åŒ–",
        "ğŸ¤– AIåŠ©æ‰‹"
    ])
    
    # ==================== Tab 1: æ•°æ®åŠ è½½ ====================
    with tab1:
        st.markdown("## ğŸ“‚ æ•°æ®åŠ è½½")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if "ä¸Šä¼ " in data_source:
                st.markdown("### ä¸Šä¼ æœ¬åœ°æ–‡ä»¶")
                st.markdown("æ”¯æŒæ ¼å¼: CSV, TXT (WoS), BibTeX, RIS")
                
                uploaded_file = st.file_uploader(
                    "æ‹–æ‹½æˆ–ç‚¹å‡»ä¸Šä¼ æ–‡ä»¶",
                    type=['csv', 'txt', 'bib', 'ris'],
                    help="æ”¯æŒWeb of Scienceã€Scopuså¯¼å‡ºæ–‡ä»¶"
                )
                
                if uploaded_file is not None:
                    try:
                        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                        file_path = f"temp_{uploaded_file.name}"
                        with open(file_path, 'wb') as f:
                            f.write(uploaded_file.getbuffer())
                        
                        # å¯¼å…¥æ–‡ä»¶
                        importer = FileImporter()
                        data = importer.import_file(file_path)
                        
                        if data is not None and len(data) > 0:
                            st.session_state.data = data
                            st.success(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡æ–‡çŒ®è®°å½•!")
                        else:
                            st.error("âŒ æ–‡ä»¶è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ ¼å¼")
                        
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        os.remove(file_path)
                        
                    except Exception as e:
                        st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
            
            elif "OpenAlex" in data_source:
                st.markdown("### ğŸŒ ä»OpenAlexè·å–æ•°æ®")
                st.markdown("OpenAlexæ˜¯å…è´¹å¼€æ”¾çš„å­¦æœ¯æ•°æ®åº“ï¼Œæ— éœ€APIå¯†é’¥")
                
                keywords = st.text_input(
                    "æœç´¢å…³é”®è¯",
                    placeholder="ä¾‹å¦‚: generative AI tourism",
                    help="è¾“å…¥è‹±æ–‡å…³é”®è¯ï¼Œå¤šä¸ªå…³é”®è¯ç”¨ç©ºæ ¼åˆ†éš”"
                )
                
                col_a, col_b = st.columns(2)
                with col_a:
                    year_start = st.number_input("èµ·å§‹å¹´ä»½", min_value=2000, max_value=2026, value=2024)
                with col_b:
                    year_end = st.number_input("ç»“æŸå¹´ä»½", min_value=2000, max_value=2026, value=2026)
                
                max_results = st.slider("æœ€å¤§è·å–æ•°é‡", 50, 500, 200)
                
                if st.button("ğŸ” å¼€å§‹è·å–", type="primary"):
                    if keywords:
                        with st.spinner("æ­£åœ¨ä»OpenAlexè·å–æ•°æ®..."):
                            try:
                                fetcher = DataFetcher()
                                papers = fetcher.fetch_papers(
                                    keywords=keywords.split(),
                                    year_start=year_start,
                                    year_end=year_end,
                                    max_results=max_results
                                )
                                # è½¬æ¢ä¸ºDataFrame
                                import pandas as pd
                                data = pd.DataFrame(papers) if papers else None
                                
                                if data is not None and len(data) > 0:
                                    st.session_state.data = data
                                    st.success(f"âœ… æˆåŠŸè·å– {len(data)} æ¡æ–‡çŒ®è®°å½•!")
                                else:
                                    st.warning("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡çŒ®ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")
                                    
                            except Exception as e:
                                st.error(f"âŒ è·å–å¤±è´¥: {str(e)}")
                    else:
                        st.warning("è¯·è¾“å…¥æœç´¢å…³é”®è¯")
            
            else:  # Demoæ•°æ®
                st.markdown("### ğŸ² ä½¿ç”¨Demoæµ‹è¯•æ•°æ®")
                st.markdown("ç”Ÿæˆ200æ¡æ¨¡æ‹Ÿè®ºæ–‡æ•°æ®ï¼Œç”¨äºæµ‹è¯•ç³»ç»ŸåŠŸèƒ½")
                
                if st.button("ğŸ“¦ åŠ è½½Demoæ•°æ®", type="primary"):
                    with st.spinner("æ­£åœ¨ç”ŸæˆDemoæ•°æ®..."):
                        try:
                            data = load_demo_data()
                            st.session_state.data = data
                            st.success(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡Demoæ•°æ®!")
                        except Exception as e:
                            st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
        
        with col2:
            st.markdown("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            if st.session_state.data is not None:
                df = st.session_state.data
                
                # ç»Ÿè®¡ä¿¡æ¯
                st.metric("è®ºæ–‡æ€»æ•°", len(df))
                if 'year' in df.columns:
                    st.metric("æ—¶é—´èŒƒå›´", f"{df['year'].min()} - {df['year'].max()}")
                if 'journal' in df.columns:
                    st.metric("æœŸåˆŠæ•°é‡", df['journal'].nunique())
                if 'citations' in df.columns:
                    st.metric("å¹³å‡è¢«å¼•", f"{df['citations'].mean():.1f}")
        
        # æ•°æ®è¡¨æ ¼å±•ç¤º
        if st.session_state.data is not None:
            st.markdown("### ğŸ“‹ æ•°æ®è¯¦æƒ…")
            
            # æ˜¾ç¤ºå‰10æ¡
            display_df = st.session_state.data.head(10).copy()
            if 'abstract' in display_df.columns:
                display_df['abstract'] = display_df['abstract'].str[:100] + '...'
            
            st.dataframe(display_df, use_container_width=True)
            
            # ä¸‹è½½æŒ‰é’®
            csv = st.session_state.data.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                "ğŸ“¥ ä¸‹è½½å®Œæ•´æ•°æ® (CSV)",
                csv,
                "ssci_data.csv",
                "text/csv"
            )
    
    # ==================== Tab 2: å…³é”®è¯åˆ†æ ====================
    with tab2:
        st.markdown("## ğŸ”‘ å…³é”®è¯åˆ†æ")
        
        if st.session_state.data is None:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€æ•°æ®åŠ è½½ã€‘æ ‡ç­¾é¡µåŠ è½½æ•°æ®")
        else:
            if st.button("ğŸš€ å¼€å§‹å…³é”®è¯åˆ†æ", type="primary"):
                with st.spinner("æ­£åœ¨åˆ†æå…³é”®è¯..."):
                    try:
                        # æ–‡æœ¬é¢„å¤„ç†
                        processor = TextProcessor()
                        processed = processor.process(st.session_state.data)
                        st.session_state.processed_data = processed
                        
                        # å…³é”®è¯åˆ†æ
                        analyzer = TrendAnalyzer()
                        results = analyzer.analyze(processed)
                        st.session_state.analysis_results = results
                        
                        st.success("âœ… åˆ†æå®Œæˆ!")
                        
                    except Exception as e:
                        st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
            
            # æ˜¾ç¤ºåˆ†æç»“æœ
            if st.session_state.analysis_results is not None:
                results = st.session_state.analysis_results
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### ğŸ“Š é«˜é¢‘å…³é”®è¯ Top 20")
                    if 'top_keywords' in results:
                        kw_df = pd.DataFrame(results['top_keywords'][:20], columns=['å…³é”®è¯', 'é¢‘æ¬¡'])
                        
                        # æ¡å½¢å›¾
                        st.bar_chart(kw_df.set_index('å…³é”®è¯'))
                        
                        # è¡¨æ ¼
                        st.dataframe(kw_df, use_container_width=True)
                
                with col2:
                    st.markdown("### ğŸ”¥ çªå‘è¯ (Burst Words)")
                    st.markdown("*è¿‘æœŸçƒ­åº¦é£™å‡çš„å…³é”®è¯*")
                    
                    if 'burst_words' in results and results['burst_words']:
                        for word, score in results['burst_words'][:10]:
                            st.markdown(f"âš¡ **{word}** (çªå‘æŒ‡æ•°: {score:.2f})")
                    else:
                        st.info("æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„çªå‘è¯")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ•³ï¸ æ½œåœ¨ç ”ç©¶ç¼ºå£")
                    
                    if 'research_gaps' in results and results['research_gaps']:
                        for i, gap in enumerate(results['research_gaps'][:5], 1):
                            st.markdown(f"ğŸ’¡ {i}. {gap}")
                    else:
                        st.info("è¯·å®ŒæˆLDAä¸»é¢˜å»ºæ¨¡ä»¥è·å–ç ”ç©¶ç¼ºå£")
    
    # ==================== Tab 3: ä¸»é¢˜å»ºæ¨¡ ====================
    with tab3:
        st.markdown("## ğŸ§  LDAä¸»é¢˜å»ºæ¨¡")
        
        if st.session_state.processed_data is None:
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆå…³é”®è¯åˆ†æ")
        else:
            col1, col2 = st.columns([1, 3])
            
            with col1:
                n_topics = st.slider("ä¸»é¢˜æ•°é‡", 4, 15, 8)
                
                if st.button("ğŸ§  è¿è¡ŒLDAå»ºæ¨¡", type="primary"):
                    with st.spinner("æ­£åœ¨è¿›è¡Œä¸»é¢˜å»ºæ¨¡..."):
                        try:
                            analyzer = TrendAnalyzer()
                            topics = analyzer.lda_topic_modeling(
                                st.session_state.processed_data, 
                                n_topics=n_topics
                            )
                            st.session_state.topics = topics
                            st.success("âœ… ä¸»é¢˜å»ºæ¨¡å®Œæˆ!")
                        except Exception as e:
                            st.error(f"âŒ å»ºæ¨¡å¤±è´¥: {str(e)}")
            
            with col2:
                if st.session_state.topics is not None:
                    st.markdown("### ğŸ“š è¯†åˆ«å‡ºçš„ç ”ç©¶ä¸»é¢˜")
                    
                    for i, topic in enumerate(st.session_state.topics, 1):
                        with st.expander(f"ğŸ“Œ ä¸»é¢˜ {i}: {topic.get('label', 'Unknown')}", expanded=(i<=3)):
                            st.markdown(f"**å…³é”®è¯**: {', '.join(topic.get('keywords', [])[:10])}")
                            if 'doc_count' in topic:
                                st.markdown(f"**ç›¸å…³è®ºæ–‡æ•°**: {topic['doc_count']}")
                            if 'representative_paper' in topic:
                                st.markdown(f"**ä»£è¡¨æ€§è®ºæ–‡**: {topic['representative_paper'][:100]}...")
    
    # ==================== Tab 4: å¯è§†åŒ– ====================
    with tab4:
        st.markdown("## ğŸ“ˆ å¯è§†åŒ–åˆ†æ")
        
        if st.session_state.analysis_results is None:
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆå…³é”®è¯åˆ†æ")
        else:
            viz_type = st.selectbox(
                "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
                ["ğŸ“Š å…³é”®è¯é¢‘ç‡å›¾", "ğŸ•¸ï¸ å…±ç°ç½‘ç»œ", "ğŸ“… å¹´åº¦è¶‹åŠ¿", "ğŸ“ˆ è¢«å¼•åˆ†æ"]
            )
            
            if "é¢‘ç‡" in viz_type:
                st.markdown("### ğŸ“Š å…³é”®è¯é¢‘ç‡åˆ†å¸ƒ")
                
                if 'top_keywords' in st.session_state.analysis_results:
                    kw_data = st.session_state.analysis_results['top_keywords'][:30]
                    df = pd.DataFrame(kw_data, columns=['keyword', 'frequency'])
                    
                    # ä½¿ç”¨StreamlitåŸç”Ÿå›¾è¡¨
                    st.bar_chart(df.set_index('keyword'))
            
            elif "å…±ç°" in viz_type:
                st.markdown("### ğŸ•¸ï¸ å…³é”®è¯å…±ç°ç½‘ç»œ")
                st.info("å…±ç°ç½‘ç»œæ˜¾ç¤ºå…³é”®è¯ä¹‹é—´çš„å…³è”å…³ç³»")
                
                if st.session_state.analysis_results and 'cooccurrence' in st.session_state.analysis_results:
                    cooc = st.session_state.analysis_results['cooccurrence']
                    
                    # æ˜¾ç¤ºå…±ç°å¯¹
                    st.markdown("**é«˜é¢‘å…±ç°è¯å¯¹:**")
                    for pair, count in list(cooc.items())[:15]:
                        st.markdown(f"- {pair[0]} â†” {pair[1]}: {count}æ¬¡")
                else:
                    st.warning("éœ€è¦å…ˆè¿è¡Œå…³é”®è¯åˆ†æ")
            
            elif "å¹´åº¦" in viz_type:
                st.markdown("### ğŸ“… å…³é”®è¯å¹´åº¦è¶‹åŠ¿")
                
                if st.session_state.data is not None and 'year' in st.session_state.data.columns:
                    yearly = st.session_state.data.groupby('year').size()
                    st.line_chart(yearly)
                    
                    st.markdown("**å„å¹´åº¦è®ºæ–‡æ•°é‡:**")
                    st.dataframe(yearly.reset_index().rename(columns={0: 'è®ºæ–‡æ•°', 'year': 'å¹´ä»½'}))
            
            elif "è¢«å¼•" in viz_type:
                st.markdown("### ğŸ“ˆ è¢«å¼•åˆ†æ")
                
                if st.session_state.data is not None and 'citations' in st.session_state.data.columns:
                    df = st.session_state.data
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ€»è¢«å¼•æ¬¡æ•°", int(df['citations'].sum()))
                    col2.metric("å¹³å‡è¢«å¼•", f"{df['citations'].mean():.1f}")
                    col3.metric("æœ€é«˜è¢«å¼•", int(df['citations'].max()))
                    
                    # è¢«å¼•åˆ†å¸ƒ
                    st.markdown("**è¢«å¼•æ¬¡æ•°åˆ†å¸ƒ:**")
                    hist_data = df['citations'].value_counts().sort_index().head(20)
                    st.bar_chart(hist_data)
                    
                    # é«˜è¢«å¼•è®ºæ–‡
                    st.markdown("**ğŸ† é«˜è¢«å¼•è®ºæ–‡ Top 10:**")
                    top_cited = df.nlargest(10, 'citations')[['title', 'year', 'citations', 'journal']]
                    st.dataframe(top_cited, use_container_width=True)
    
    # ==================== Tab 5: AIåŠ©æ‰‹ ====================
    with tab5:
        st.markdown("## ğŸ¤– AIè¾…åŠ©åˆ†æ")
        
        st.markdown("""
        AIåŠ©æ‰‹å¯ä»¥å¸®ä½ ï¼š
        - ğŸ¯ ç”Ÿæˆåˆ›æ–°é€‰é¢˜å»ºè®®
        - ğŸ“ æä¾›è®ºæ–‡å†™ä½œæ¡†æ¶
        - ğŸ” è¯†åˆ«ç ”ç©¶ç¼ºå£
        - ğŸ’¡ æ¨èç ”ç©¶æ–¹æ³•
        """)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰API key
        api_key = os.environ.get('ANTHROPIC_API_KEY', '')
        
        if not api_key:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ° ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
            st.markdown("""
            **è®¾ç½®æ–¹æ³•:**
            ```bash
            # Windows
            set ANTHROPIC_API_KEY=your-api-key
            
            # Mac/Linux
            export ANTHROPIC_API_KEY=your-api-key
            ```
            
            æ²¡æœ‰API Keyä¹Ÿå¯ä»¥ä½¿ç”¨åŸºäºè§„åˆ™çš„å»ºè®®åŠŸèƒ½ğŸ‘‡
            """)
        
        st.markdown("---")
        
        analysis_type = st.selectbox(
            "é€‰æ‹©åˆ†æç±»å‹",
            [
                "ğŸ¯ ç”Ÿæˆé€‰é¢˜å»ºè®®",
                "ğŸ“ è®ºæ–‡å†™ä½œæ¡†æ¶",
                "ğŸ” ç ”ç©¶ç¼ºå£æ·±åº¦åˆ†æ",
                "ğŸ’¬ è‡ªå®šä¹‰é—®é¢˜"
            ]
        )
        
        if "é€‰é¢˜" in analysis_type:
            st.markdown("### ğŸ¯ AIé€‰é¢˜å»ºè®®")
            
            focus_area = st.text_input(
                "ä½ çš„ç ”ç©¶å…´è¶£æ–¹å‘",
                placeholder="ä¾‹å¦‚: AIåœ¨æ—…æ¸¸è¥é”€ä¸­çš„åº”ç”¨",
                help="è¾“å…¥ä½ æ„Ÿå…´è¶£çš„ç ”ç©¶æ–¹å‘ï¼ŒAIä¼šç»“åˆæ–‡çŒ®åˆ†æç»™å‡ºå»ºè®®"
            )
            
            if st.button("âœ¨ ç”Ÿæˆé€‰é¢˜å»ºè®®", type="primary"):
                with st.spinner("AIæ­£åœ¨åˆ†æå¹¶ç”Ÿæˆå»ºè®®..."):
                    try:
                        advisor = AIAdvisor()
                        
                        context = {
                            'data': st.session_state.data,
                            'analysis': st.session_state.analysis_results,
                            'topics': st.session_state.topics,
                            'focus': focus_area
                        }
                        
                        suggestions = advisor.generate_topic_suggestions(context)
                        
                        st.markdown("### ğŸ“‹ é€‰é¢˜å»ºè®®")
                        st.markdown(suggestions)
                        
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        elif "å†™ä½œ" in analysis_type:
            st.markdown("### ğŸ“ è®ºæ–‡å†™ä½œæ¡†æ¶")
            
            paper_topic = st.text_input(
                "ä½ çš„è®ºæ–‡é¢˜ç›®/ä¸»é¢˜",
                placeholder="ä¾‹å¦‚: ChatGPTå¯¹æ¸¸å®¢å†³ç­–è¡Œä¸ºçš„å½±å“ç ”ç©¶"
            )
            
            if st.button("ğŸ“„ ç”Ÿæˆå†™ä½œæ¡†æ¶", type="primary"):
                with st.spinner("ç”Ÿæˆå†™ä½œæ¡†æ¶..."):
                    try:
                        advisor = AIAdvisor()
                        framework = advisor.generate_writing_framework(paper_topic)
                        
                        st.markdown("### ğŸ“‘ å»ºè®®çš„è®ºæ–‡æ¡†æ¶")
                        st.markdown(framework)
                        
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        
        elif "ç¼ºå£" in analysis_type:
            st.markdown("### ğŸ” ç ”ç©¶ç¼ºå£æ·±åº¦åˆ†æ")
            
            if st.session_state.analysis_results is None:
                st.warning("è¯·å…ˆå®Œæˆå…³é”®è¯åˆ†æä»¥è·å¾—æ›´å‡†ç¡®çš„ç¼ºå£è¯†åˆ«")
            
            if st.button("ğŸ” åˆ†æç ”ç©¶ç¼ºå£", type="primary"):
                with st.spinner("æ·±åº¦åˆ†æç ”ç©¶ç¼ºå£..."):
                    try:
                        advisor = AIAdvisor()
                        
                        context = {
                            'data': st.session_state.data,
                            'analysis': st.session_state.analysis_results,
                            'topics': st.session_state.topics
                        }
                        
                        gaps = advisor.analyze_research_gaps(context)
                        
                        st.markdown("### ğŸ•³ï¸ ç ”ç©¶ç¼ºå£åˆ†ææŠ¥å‘Š")
                        st.markdown(gaps)
                        
                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
        
        else:  # è‡ªå®šä¹‰é—®é¢˜
            st.markdown("### ğŸ’¬ è‡ªå®šä¹‰é—®é¢˜")
            
            user_question = st.text_area(
                "è¾“å…¥ä½ çš„é—®é¢˜",
                placeholder="ä¾‹å¦‚: å¦‚ä½•åœ¨è®ºæ–‡ä¸­å¼ºè°ƒæ–¹æ³•è®ºåˆ›æ–°ï¼ŸSSCIå®¡ç¨¿äººæœ€çœ‹é‡ä»€ä¹ˆï¼Ÿ",
                height=100
            )
            
            if st.button("ğŸ’¡ è·å–å»ºè®®", type="primary"):
                if user_question:
                    with st.spinner("æ€è€ƒä¸­..."):
                        try:
                            advisor = AIAdvisor()
                            
                            context = {
                                'data': st.session_state.data,
                                'analysis': st.session_state.analysis_results,
                                'question': user_question
                            }
                            
                            answer = advisor.answer_question(context)
                            
                            st.markdown("### ğŸ’¡ å»ºè®®")
                            st.markdown(answer)
                            
                        except Exception as e:
                            st.error(f"è·å–å»ºè®®å¤±è´¥: {str(e)}")
                else:
                    st.warning("è¯·è¾“å…¥é—®é¢˜")
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; color: #888; font-size: 0.9rem;">
            ğŸ“Š SSCIæ—…æ¸¸å­¦æœ¯è¶‹åŠ¿åˆ†æç³»ç»Ÿ v2.0 | 
            Made with â¤ï¸ by Claude AI
        </div>
        """,
        unsafe_allow_html=True
    )


if __name__ == "__main__":
    main()
